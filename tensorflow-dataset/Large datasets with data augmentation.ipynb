{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow version 1.4\n",
    "\n",
    "Note on tensorflow version:\n",
    "\n",
    "> This notebook works with tensorflow 1.4. It uses the Dataset API of *tf.data*. In previous versions, the Dataset API was in *tf.contrib.data*. Although I did not test it, it may be possible to use this notebook with tensorflow 1.3 by replacing *tf.data* by *tf.contrib.data*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "height = 5\n",
    "width = 5\n",
    "\n",
    "# Create random files containing raw matrix of shape 5x5\n",
    "for i in range(2):\n",
    "    for j in range(3):\n",
    "        # Create matrix with fake data\n",
    "        matrix = np.zeros((height,width)) + i + (j*10)\n",
    "        # Save matrix as raw float32 file\n",
    "        matrix.astype('float32').tofile('data/file_' + str(i) + '_' + str(j) + '.raw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 11.,  11.,  11.,  11.,  11.],\n",
       "       [ 11.,  11.,  11.,  11.,  11.],\n",
       "       [ 11.,  11.,  11.,  11.,  11.],\n",
       "       [ 11.,  11.,  11.,  11.,  11.],\n",
       "       [ 11.,  11.,  11.,  11.,  11.]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check one of the generated files\n",
    "matrix = np.fromfile('data/file_1_1.raw', dtype=np.float32)\n",
    "matrix = matrix.reshape((height,width))\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create parser\n",
    "# Args: filenames\n",
    "# Returns: tensor containing read and decoded element\n",
    "def _parse_data(filename0, filename1, label):\n",
    "    # Read and decode first file\n",
    "    matrix0 = tf.read_file(filename0)\n",
    "    matrix0 = tf.decode_raw(matrix0, out_type=tf.float32)\n",
    "    matrix0 = tf.reshape(matrix0, [height,width])\n",
    "    \n",
    "    # Read and decode second file\n",
    "    matrix1 = tf.read_file(filename1)\n",
    "    matrix1 = tf.decode_raw(matrix1, out_type=tf.float32)\n",
    "    matrix1 = tf.reshape(matrix1, [height,width])\n",
    "    \n",
    "    # Stack the two elements together\n",
    "    X = tf.stack([matrix0, matrix1])\n",
    "    \n",
    "    # Get label (you could implement more complex logic here if needed)\n",
    "    y = label\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow' has no attribute 'data'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-f119016d2235>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[1;31m# Create datasets for each filenames list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfrom_tensor_slices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf_filenames0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf_filenames1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_parse_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow' has no attribute 'data'"
     ]
    }
   ],
   "source": [
    "# Get the filenames lists\n",
    "filenames0 = ['data/file_0_0.raw', 'data/file_0_1.raw', 'data/file_0_2.raw']\n",
    "filenames1 = ['data/file_1_0.raw', 'data/file_1_1.raw', 'data/file_1_2.raw']\n",
    "\n",
    "# Create tensorflow constant containing the filenames\n",
    "tf_filenames0 = tf.constant(filenames0)\n",
    "tf_filenames1 = tf.constant(filenames1)\n",
    "\n",
    "# Create labels dataset\n",
    "labels = tf.constant([15, 25, 10])\n",
    "\n",
    "# Create datasets for each filenames list\n",
    "dataset = tf.data.Dataset.from_tensor_slices((tf_filenames0, tf_filenames1, labels))\n",
    "\n",
    "dataset = dataset.map(_parse_data)\n",
    "\n",
    "# create TensorFlow Iterator object\n",
    "iterator = dataset.make_one_shot_iterator()\n",
    "next_element = iterator.get_next()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "\n",
    "    # initialize the iterator on the training data\n",
    "    sess.run(init_op)\n",
    "\n",
    "    # get each element of the training dataset until the end is reached\n",
    "    while True:\n",
    "        try:\n",
    "            elem = sess.run(next_element)\n",
    "            print(elem)\n",
    "        except tf.errors.OutOfRangeError:\n",
    "            print(\"End of dataset.\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
